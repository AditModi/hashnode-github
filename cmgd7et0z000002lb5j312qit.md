---
title: "Speaking at HashiConf 2025: Making GenAI Real (and Responsible)"
datePublished: Sun Oct 05 2025 04:30:35 GMT+0000 (Coordinated Universal Time)
cuid: cmgd7et0z000002lb5j312qit
slug: speaking-at-hashiconf-2025-making-genai-real-and-responsible
tags: aws, hashicorp

---

A few days ago, I had the opportunity to speak at **HashiConf 2025** in San Francisco — and it was one of the most rewarding experiences I’ve had as part of the HashiCorp community.

My talk was titled:  
**“RAG meets reality: Building secure, compliant GenAI with Vault and Bedrock.”**  
It was part of the hallway track — an intentionally informal, open space that allows for real conversations, immediate feedback, and honest questions. And I genuinely enjoyed every minute of it.

#### Why This Talk, and Why Now?

Over the past year, I've spent a lot of time working with teams at the intersection of **AI and infrastructure**, especially those trying to move **Generative AI** from prototype to production.

One theme comes up again and again:

> Everyone's excited about GenAI — but when it’s time to put something real into production, **security, compliance, and auditability become major blockers**.

We don’t talk about it enough — but in enterprise environments, having a cool model isn’t enough. You need to know who accessed what, which inputs and outputs are being logged, how secrets are managed, and whether you’re in line with internal or industry regulations. Without that foundation, it’s hard to scale anything responsibly.

So in this session, I focused on how tools like **HashiCorp Vault** and **Amazon Bedrock** can be used together to build GenAI systems that are:

* **Secure by default**
    
* **Auditable and policy-driven**
    
* **Compliant with enterprise standards**
    
* And still… powerful and flexible enough for real use cases
    

#### Not Just Tech, But Culture

One thing I emphasized in the talk is that this isn’t just a technical problem — it’s a **cultural one**. Security and compliance often get bolted on at the end, treated as checkboxes. But the teams that are winning in production are the ones who **build with those concerns in mind from day one.**

It’s not always glamorous work, but it’s necessary if we want to ship AI systems that people can trust — especially in regulated industries or customer-facing applications.

#### The Experience of Speaking

What made this session even more special was the setting. HashiConf isn’t just a conference — it’s a room full of builders, practitioners, operators, and engineers who *get it*. They’re living the same problems, asking the same hard questions, and genuinely want to help each other get better.

The questions I got after the session, the hallway chats that followed — those were the real highlights. You can tell when a topic resonates because people don’t just listen, they start brainstorming out loud with you.

---

### Gratitude & Takeaways

Huge thanks to the **HashiCorp team** for curating a space where these kinds of conversations can happen. And to the **HashiCorp Ambassador program** — I’ve learned so much from being part of this community.

If you’re working on GenAI and facing friction around secrets management, compliance, or observability — reach out. I’d love to hear what challenges you’re facing and share more about what’s worked (and not worked) for us.

And if you’re thinking about speaking at a future HashiConf or community event: **do it**. The best ideas don’t come from big stages — they come from real experience. And someone out there is probably looking for exactly the story you have to share.